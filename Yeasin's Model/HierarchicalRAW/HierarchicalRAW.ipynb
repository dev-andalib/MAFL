{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter, defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score, \n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ee41b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r\"E:\\Thesis\\Defence\\AnD\\Version_3\\Recent_UpdatedNB15.csv\")\n",
    "print(f\"Dataset Shape: {df1.shape}\")\n",
    "display(df1.head(10))\n",
    "display(df1.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211fd9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_city = LabelEncoder()\n",
    "df1['is_sm_ips_ports'] = le_city.fit_transform(df1['is_sm_ips_ports'])\n",
    "df1['label'] = le_city.fit_transform(df1['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7561072",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d5e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df1.columns if col not in ['label', 'attack_cat']]\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Feature columns: {len(feature_cols)} columns\")\n",
    "\n",
    "# Cell 4: Create correlation matrix with binary label\n",
    "features_with_label = feature_cols + ['label']\n",
    "corr_matrix_binary = df1[features_with_label].corr()\n",
    "print(f\"Correlation matrix shape: {corr_matrix_binary.shape}\")\n",
    "\n",
    "# Cell 5: Display correlation with binary label\n",
    "label_correlations = corr_matrix_binary['label'].drop('label').sort_values(key=abs, ascending=False)\n",
    "print(\"Top 20 features correlated with binary label:\")\n",
    "print(label_correlations.head(20))\n",
    "\n",
    "# Cell 6: Create correlation matrix with multi-class label\n",
    "features_with_attack_cat = feature_cols + ['attack_cat']\n",
    "corr_matrix_multiclass = df1[features_with_attack_cat].corr()\n",
    "attack_cat_correlations = corr_matrix_multiclass['attack_cat'].drop('attack_cat').sort_values(key=abs, ascending=False)\n",
    "print(\"Top 20 features correlated with attack_cat:\")\n",
    "print(attack_cat_correlations.head(20))\n",
    "\n",
    "# Cell 7: Visualize correlation matrix - Binary Label (Top 20 features)\n",
    "top_20_features_binary = label_correlations.head(20).index.tolist()\n",
    "corr_subset_binary = df1[top_20_features_binary + ['label']].corr()\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(corr_subset_binary, annot=True, cmap='RdBu_r', center=0, \n",
    "            square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix: Top 20 Features + Binary Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 8: Visualize correlation matrix - Multi-class Label (Top 20 features)\n",
    "top_20_features_multiclass = attack_cat_correlations.head(20).index.tolist()\n",
    "corr_subset_multiclass = df1[top_20_features_multiclass + ['attack_cat']].corr()\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(corr_subset_multiclass, annot=True, cmap='RdBu_r', center=0, \n",
    "            square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix: Top 20 Features + Multi-class Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 9: Full correlation matrix (all features)\n",
    "full_corr_matrix = df1.corr()\n",
    "print(f\"Full correlation matrix shape: {full_corr_matrix.shape}\")\n",
    "\n",
    "# Cell 10: Visualize full correlation matrix (heatmap)\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(full_corr_matrix, cmap='RdBu_r', center=0, square=True, \n",
    "            cbar_kws={\"shrink\": .5})\n",
    "plt.title('Full Correlation Matrix - All Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 11: Extract correlations with labels only\n",
    "label_corr_summary = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'binary_label_corr': [corr_matrix_binary.loc[feature, 'label'] for feature in feature_cols],\n",
    "    'attack_cat_corr': [corr_matrix_multiclass.loc[feature, 'attack_cat'] for feature in feature_cols]\n",
    "})\n",
    "label_corr_summary['abs_binary_corr'] = abs(label_corr_summary['binary_label_corr'])\n",
    "label_corr_summary['abs_attack_cat_corr'] = abs(label_corr_summary['attack_cat_corr'])\n",
    "label_corr_summary = label_corr_summary.sort_values('abs_binary_corr', ascending=False)\n",
    "\n",
    "print(\"Feature correlations with both labels:\")\n",
    "print(label_corr_summary.head(15))\n",
    "\n",
    "# Cell 12: Bar plot - Binary label correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_15_binary = label_corr_summary.head(15)\n",
    "colors = ['red' if x < 0 else 'blue' for x in top_15_binary['binary_label_corr']]\n",
    "plt.barh(range(len(top_15_binary)), top_15_binary['binary_label_corr'], color=colors, alpha=0.7)\n",
    "plt.yticks(range(len(top_15_binary)), top_15_binary['feature'])\n",
    "plt.xlabel('Correlation with Binary Label')\n",
    "plt.title('Top 15 Features - Binary Label Correlation')\n",
    "plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 13: Bar plot - Multi-class label correlations\n",
    "label_corr_summary_mc = label_corr_summary.sort_values('abs_attack_cat_corr', ascending=False)\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_15_multiclass = label_corr_summary_mc.head(15)\n",
    "colors_mc = ['red' if x < 0 else 'green' for x in top_15_multiclass['attack_cat_corr']]\n",
    "plt.barh(range(len(top_15_multiclass)), top_15_multiclass['attack_cat_corr'], color=colors_mc, alpha=0.7)\n",
    "plt.yticks(range(len(top_15_multiclass)), top_15_multiclass['feature'])\n",
    "plt.xlabel('Correlation with Attack Category')\n",
    "plt.title('Top 15 Features - Multi-class Label Correlation')\n",
    "plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 14: Correlation comparison scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(label_corr_summary['abs_binary_corr'], label_corr_summary['abs_attack_cat_corr'], \n",
    "           alpha=0.6, s=50)\n",
    "plt.plot([0, 1], [0, 1], 'r--', alpha=0.8)\n",
    "plt.xlabel('Absolute Correlation with Binary Label')\n",
    "plt.ylabel('Absolute Correlation with Attack Category')\n",
    "plt.title('Feature Correlations: Binary vs Multi-class')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 15: Save correlation matrices\n",
    "print(\"Correlation matrices created:\")\n",
    "print(f\"- corr_matrix_binary: shape {corr_matrix_binary.shape}\")\n",
    "print(f\"- corr_matrix_multiclass: shape {corr_matrix_multiclass.shape}\")\n",
    "print(f\"- full_corr_matrix: shape {full_corr_matrix.shape}\")\n",
    "print(f\"- label_corr_summary: feature correlations with both labels\")\n",
    "print(\"Analysis completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04f202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c98a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_bin = df1['label']\n",
    "unique_labels = labels_bin.unique()\n",
    "print(f\"Number of unique labels: {len(unique_labels)}\")\n",
    "print(f\"Unique labels: {unique_labels}\")\n",
    "print(f\"Label data type: {labels_bin.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb99f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts_bin = labels_bin.value_counts()\n",
    "print(\"Label Distribution:\")\n",
    "print(label_counts_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count = label_counts_bin.max()\n",
    "min_count = label_counts_bin.min()\n",
    "balance_ratio = max_count / min_count\n",
    "print(f\"Most frequent class: {label_counts_bin.index[0]} ({max_count} samples)\")\n",
    "print(f\"Least frequent class: {label_counts_bin.index[-1]} ({min_count} samples)\")\n",
    "print(f\"Imbalance ratio: {balance_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_bin.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a7181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_att = df1['attack_cat']\n",
    "unique_labels = labels_att.unique()\n",
    "print(f\"Number of unique labels: {len(unique_labels)}\")\n",
    "print(f\"Unique labels: {unique_labels}\")\n",
    "print(f\"Label data type: {labels_att.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7794a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = labels_att.value_counts()\n",
    "print(\"Label Distribution:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b108e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_percentages = labels_att.value_counts(normalize=True) * 100\n",
    "label_distribution = pd.DataFrame({\n",
    "    'Count': label_counts,\n",
    "    'Percentage': label_percentages\n",
    "})\n",
    "print(label_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7863e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count = label_counts.max()\n",
    "min_count = label_counts.min()\n",
    "balance_ratio = max_count / min_count\n",
    "print(f\"Most frequent class: {label_counts.index[0]} ({max_count} samples)\")\n",
    "print(f\"Least frequent class: {label_counts.index[-1]} ({min_count} samples)\")\n",
    "print(f\"Imbalance ratio: {balance_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8534a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_att.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea3527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(columns=[\"label\", \"attack_cat\"])\n",
    "y = df1[\"label\"]\n",
    "y_att = df1[\"attack_cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9701f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, attack_train, attack_test = train_test_split(X, y, y_att, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "X_binned = X.apply(lambda col: pd.qcut(col, q=3, labels=False, duplicates='drop'))\n",
    "X_binned_tensor = torch.tensor(X_binned.values, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8edf065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "def comprehensive_chi2_selection(X_train, y_train, n_features=20, n_bins=10):\n",
    "    results = []\n",
    "    \n",
    "    discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
    "    X_binned = pd.DataFrame(\n",
    "        discretizer.fit_transform(X_train),\n",
    "        columns=X_train.columns,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    \n",
    "    for col in X_binned.columns:\n",
    "\n",
    "        contingency = pd.crosstab(X_binned[col], y_train)\n",
    "        \n",
    "    \n",
    "        chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "        \n",
    "        n = contingency.sum().sum()\n",
    "        min_dim = min(contingency.shape[0], contingency.shape[1]) - 1\n",
    "        cramers_v = np.sqrt(chi2 / (n * min_dim)) if min_dim > 0 else 0\n",
    "        \n",
    "        results.append({\n",
    "            'feature': col,\n",
    "            'chi2': chi2,\n",
    "            'p_value': p_value,\n",
    "            'cramers_v': cramers_v,\n",
    "            'dof': dof,\n",
    "            'n_bins_used': contingency.shape[0]\n",
    "        })\n",
    "    \n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('chi2', ascending=False)\n",
    "    \n",
    "    display(results_df)\n",
    "    print(\"\\nChi-Square Feature Selection Results:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Feature':<25} {'Chi2':>12} {'P-value':>12} {'CramÃ©r V':>10} {'DoF':>5}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for idx, row in results_df.head(n_features).iterrows():\n",
    "        print(f\"{row['feature']:<25} {row['chi2']:>12.3f} {row['p_value']:>12.3e} \"\n",
    "              f\"{row['cramers_v']:>10.3f} {row['dof']:>5}\")\n",
    "    \n",
    "    for idx, row in results_df.iterrows():\n",
    "        if row['p_value'] > 0.05:\n",
    "            print(f\" {row['feature']} has p-value > 0.05 (not statistically significant)\")\n",
    "    \n",
    "    \n",
    "    top_features = results_df.head(n_features)['feature'].tolist()\n",
    "    \n",
    "    return top_features, results_df, discretizer\n",
    "\n",
    "\n",
    "top_features, chi2_results, discretizer = comprehensive_chi2_selection(\n",
    "    X_train, y_train, n_features=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4946716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import chi2, SelectKBest\n",
    "# selector = SelectKBest(chi2, k=20)\n",
    "# selector.fit(X_train, y_train)\n",
    "\n",
    "# selected_features = X_train.columns[selector.get_support()].tolist()\n",
    "# print(\"Top 20 features selected by Chi-Square:\")\n",
    "# print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['sttl', 'dttl', 'ct_state_ttl', 'rate', 'sload', 'dpkts', \n",
    "                    'dload', 'dinpkt', 'dur', 'proto', 'state', 'dmean', \n",
    "                    'sbytes', 'sinpkt', 'spkts', 'sjit', 'dbytes', \n",
    "                    'ct_dst_sport_ltm', 'dloss', 'ct_srv_dst']\n",
    "\n",
    "\n",
    "X_selected = X_train[selected_features]\n",
    "\n",
    "\n",
    "correlation_matrix = X_selected.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask upper triangle\n",
    "sns.heatmap(correlation_matrix, \n",
    "            mask=mask, \n",
    "            cmap='coolwarm', \n",
    "            center=0,\n",
    "            annot=True, \n",
    "            fmt='.2f',\n",
    "            square=True,\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b22d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = ['sttl', 'dttl', 'ct_state_ttl', 'rate', 'sload', 'dpkts', \n",
    "                    'dload', 'dinpkt', 'dur', 'proto', 'state', 'dmean', \n",
    "                    'sbytes', 'sinpkt', 'spkts', 'sjit', 'dbytes', \n",
    "                    'ct_dst_sport_ltm', 'dloss', 'ct_srv_dst']\n",
    "\n",
    "features_to_remove = ['spkts', 'dbytes', 'dloss']\n",
    "remaining_features = [f for f in original_features if f not in features_to_remove]\n",
    "\n",
    "print(f\"Remaining features after removal ({len(remaining_features)}):\")\n",
    "print(remaining_features)\n",
    "\n",
    "\n",
    "additional_features = ['ct_src_dport_ltm', 'ackdat', 'synack']  \n",
    "\n",
    "final_20_features = remaining_features + additional_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26351da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected = X_train[final_20_features]\n",
    "\n",
    "\n",
    "correlation_matrix = X_selected.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask upper triangle\n",
    "sns.heatmap(correlation_matrix, \n",
    "            mask=mask, \n",
    "            cmap='coolwarm', \n",
    "            center=0,\n",
    "            annot=True, \n",
    "            fmt='.2f',\n",
    "            square=True,\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7abf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eddur porjonto kichu kora lagbe nah, just permuatation dea check korte hobe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalNIDS(nn.Module):\n",
    "    def __init__(self, input_features=20, seq_length=10, num_attack_types=9):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1_3 = nn.Conv1d(input_features, 16, kernel_size=3, padding=1)\n",
    "        self.conv1_5 = nn.Conv1d(input_features, 8, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(24)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(24, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=32,\n",
    "            hidden_size=16,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "        \n",
    "        self.binary_head = nn.Sequential(\n",
    "            nn.Linear(32, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(24, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 1)\n",
    "        )\n",
    "        \n",
    "        self.multiclass_head = nn.Sequential(\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, num_attack_types)\n",
    "        )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LSTM):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        nn.init.xavier_uniform_(param.data)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        nn.init.orthogonal_(param.data)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.constant_(param.data, 0)\n",
    "    \n",
    "    def attention_net(self, lstm_output):\n",
    "        attention_scores = self.attention(lstm_output)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "        weighted_output = torch.sum(lstm_output * attention_weights, dim=1)\n",
    "        return weighted_output\n",
    "    \n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        conv_3 = self.conv1_3(x)\n",
    "        conv_5 = self.conv1_5(x)\n",
    "        x = torch.cat([conv_3, conv_5], dim=1)\n",
    "        \n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        lstm_out, _ = self.bilstm(x)\n",
    "        \n",
    "        features = self.attention_net(lstm_out)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def forward(self, x, stage='both'):\n",
    "        features = self.extract_features(x)\n",
    "        \n",
    "        if stage == 'binary' or stage == 'both':\n",
    "            binary_output = torch.sigmoid(self.binary_head(features))\n",
    "            \n",
    "        if stage == 'multiclass' or stage == 'both':\n",
    "            multiclass_output = self.multiclass_head(features)\n",
    "            \n",
    "        if stage == 'binary':\n",
    "            return binary_output\n",
    "        elif stage == 'multiclass':\n",
    "            return multiclass_output\n",
    "        else:\n",
    "            return binary_output, multiclass_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f9f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X_train[final_20_features]  \n",
    "X_test_selected = X_test[final_20_features]\n",
    "\n",
    "X_trainfinal, X_val, y_trainfinal, y_val, attack_trainfinal, attack_val = train_test_split(\n",
    "    X_train_selected, y_train, attack_train, \n",
    "    test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "custom_df = pd.concat([X_trainfinal, attack_trainfinal, y_trainfinal], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "display(custom_df.head(10))\n",
    "\n",
    "\n",
    "print(\"Attack label distribution:\")\n",
    "print(custom_df['attack_cat'].value_counts().sort_index())\n",
    "print(custom_df['label'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b44781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second check done till here (Friday - 08/ 08/ 2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab19b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# attack_counts = {1: 37567, 2: 28462, 3: 15582, 4: 10571, \n",
    "#                  5: 8913, 6: 1722, 7: 1507, 8: 953, 9: 113}\n",
    "\n",
    "\n",
    "normal_mask = attack_trainfinal == 0\n",
    "attack_mask = attack_trainfinal > 0\n",
    "\n",
    "X_normal = X_trainfinal[normal_mask]\n",
    "X_attacks = X_trainfinal[attack_mask]\n",
    "attack_labels = attack_trainfinal[attack_mask]\n",
    "benign_labels = attack_trainfinal[normal_mask]\n",
    "\n",
    "\n",
    "print(f\"Original attack distribution: {Counter(attack_labels)}\")\n",
    "print(f\"Number of normal samples: {len(X_normal)}\")\n",
    "print(f\"Number of attack samples: {len(X_attacks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa13c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame(X_attacks)\n",
    "df_temp['attack_label'] = attack_labels\n",
    "\n",
    "display(df_temp.head(10))\n",
    "display(df_temp.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp1 = pd.DataFrame(X_normal)\n",
    "df_temp1['normal_label'] = benign_labels\n",
    "\n",
    "display(df_temp1.head(10))\n",
    "display(df_temp1.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736200ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed the label problem faced earlier, here check for sanity too. 08/ 08/ 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785995c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y_binary, y_attack, seq_length=10):\n",
    "    num_samples = len(X) - seq_length + 1\n",
    "    \n",
    "    # Pre-allocate arrays for efficiency\n",
    "    X_seq = np.zeros((num_samples, seq_length, X.shape[1]))\n",
    "    y_binary_seq = np.zeros(num_samples)\n",
    "    y_attack_seq = np.zeros(num_samples, dtype=int)\n",
    "    \n",
    "    if hasattr(y_binary, 'iloc'):\n",
    "        y_binary = y_binary.values\n",
    "    if hasattr(y_attack, 'iloc'):\n",
    "        y_attack = y_attack.values\n",
    "    \n",
    "    # Sliding window.\n",
    "    for i in range(num_samples):\n",
    "        X_seq[i] = X[i:i+seq_length]\n",
    "        y_binary_seq[i] = y_binary[i+seq_length-1]\n",
    "        y_attack_seq[i] = y_attack[i+seq_length-1]\n",
    "    \n",
    "    return X_seq, y_binary_seq, y_attack_seq\n",
    "\n",
    "X_train_seq, y_binary_train_seq, y_attack_train_seq = create_sequences(\n",
    "    X_train_selected, \n",
    "    y_train, \n",
    "    attack_train,\n",
    "    seq_length=10\n",
    ")\n",
    "\n",
    "# Validation data (no SMOTE applied)\n",
    "X_val_seq, y_binary_val_seq, y_attack_val_seq = create_sequences(\n",
    "    X_val, \n",
    "    y_val,\n",
    "    attack_val,\n",
    "    seq_length=10\n",
    ")\n",
    "\n",
    "# Test data (no SMOTE applied)\n",
    "X_test_seq, y_binary_test_seq, y_attack_test_seq = create_sequences(\n",
    "    X_test_selected,  \n",
    "    y_test,\n",
    "    attack_test,\n",
    "    seq_length=10\n",
    ")\n",
    "\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train_seq)\n",
    "y_binary_train_tensor = torch.FloatTensor(y_binary_train_seq)\n",
    "y_attack_train_tensor = torch.LongTensor(y_attack_train_seq)\n",
    "\n",
    "X_val_tensor = torch.FloatTensor(X_val_seq)\n",
    "y_binary_val_tensor = torch.FloatTensor(y_binary_val_seq)\n",
    "y_attack_val_tensor = torch.LongTensor(y_attack_val_seq)\n",
    "\n",
    "X_test_tensor = torch.FloatTensor(X_test_seq)\n",
    "y_binary_test_tensor = torch.FloatTensor(y_binary_test_seq)\n",
    "y_attack_test_tensor = torch.LongTensor(y_attack_test_seq)\n",
    "\n",
    "print(f\"\\nSequence shapes:\")\n",
    "print(f\"Training: {X_train_tensor.shape} (samples, seq_length, features)\")\n",
    "print(f\"Validation: {X_val_tensor.shape}\")\n",
    "print(f\"Test: {X_test_tensor.shape}\")\n",
    "\n",
    "# Class distributions after sequence creation\n",
    "print(f\"\\nBinary distribution in sequences:\")\n",
    "print(f\"Train - Normal: {(y_binary_train_tensor == 0).sum()}, Attack: {(y_binary_train_tensor == 1).sum()}\")\n",
    "print(f\"Val - Normal: {(y_binary_val_tensor == 0).sum()}, Attack: {(y_binary_val_tensor == 1).sum()}\")\n",
    "print(f\"Test - Normal: {(y_binary_test_tensor == 0).sum()}, Attack: {(y_binary_test_tensor == 1).sum()}\")\n",
    "\n",
    "# Attack type distribution\n",
    "train_attack_dist = Counter(y_attack_train_tensor[y_binary_train_tensor == 1].numpy())\n",
    "print(f\"\\nAttack distribution in training sequences:\")\n",
    "for attack_type, count in sorted(train_attack_dist.items()):\n",
    "    print(f\"Attack_{attack_type}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec121bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"=== SEQUENCE DATA ===\")\n",
    "# if 'X_train_seq' in globals():\n",
    "#     print(f\"Training sequences shape: {X_train_seq.shape}\")\n",
    "#     print(f\"Training binary seq labels shape: {y_binary_train_seq.shape}\")\n",
    "#     print(f\"Training attack seq labels shape: {y_attack_train_seq.shape}\")\n",
    "    \n",
    "#     print(\"\\nSequence label distributions:\")\n",
    "#     print(f\"  Binary: {Counter(y_binary_train_seq)}\")\n",
    "#     print(f\"  Attack: {Counter(y_attack_train_seq)}\")\n",
    "# else:\n",
    "#     print(\"Sequences not created yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b3f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 \n",
    "# Training dataset (with SMOTE)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_binary_train_tensor, y_attack_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Setting to 0 jodi multiprocessing errors\n",
    "    pin_memory=True if torch.cuda.is_available() else False  # GPU optimization\n",
    ")\n",
    "\n",
    "# Validation dataset (no SMOTE)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_binary_val_tensor, y_attack_val_tensor)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# Test dataset (no SMOTE) \n",
    "test_dataset = TensorDataset(X_test_tensor, y_binary_test_tensor, y_attack_test_tensor)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# Attack-only loader for multiclass training\n",
    "attack_mask_train = y_binary_train_tensor == 1\n",
    "X_train_attacks = X_train_tensor[attack_mask_train]\n",
    "y_train_attacks = y_attack_train_tensor[attack_mask_train]\n",
    "\n",
    "multiclass_dataset = TensorDataset(X_train_attacks, y_train_attacks)\n",
    "multiclass_loader = DataLoader(\n",
    "    multiclass_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "print(f\"\\nDataLoader ready:\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "print(f\"Multiclass batches: {len(multiclass_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda97cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check till here, Now next task is to work on the pos_weight and dynamic weighting for model to classify better in Multi Class Classification task\n",
    "\n",
    "# Edddur porjonto ekbar check dewa lagbe (peer-review) - {Reviewed once and made a bit modular addressing previous issues - 08/ 08/ 2025}\n",
    "\n",
    "# porer theke tunning shuru korlam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6aaef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_counts = Counter(y_binary_train_tensor.numpy())\n",
    "num_normal = binary_counts[0]\n",
    "num_attack = binary_counts[1]\n",
    "\n",
    "# pos_weight = torch.tensor([num_normal / num_attack])\n",
    "# pos_weight = torch.tensor([num_attack/ num_normal])\n",
    "pos_weight = torch.tensor(1)\n",
    "\n",
    "\n",
    "print(f\"Binary Classification:\")\n",
    "print(f\"Normal samples: {num_normal}\")\n",
    "print(f\"Attack samples: {num_attack}\")\n",
    "print(f\"Positive weight: {pos_weight.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e86de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vanilla\n",
    "\n",
    "# attack_counts = Counter(y_train_attacks.numpy())\n",
    "# total_attacks = len(y_train_attacks)\n",
    "\n",
    "# # Create weights for classes 0-8 (model's output space)\n",
    "# class_weights = []\n",
    "# for i in range(9):  # 0-8 for model's 9 output classes\n",
    "#     # Map back to original labels (1-9)\n",
    "#     original_label = i + 1\n",
    "#     count = attack_counts.get(original_label, 1)\n",
    "#     weight = total_attacks / (9 * count)\n",
    "#     class_weights.append(weight)\n",
    "\n",
    "# multiclass_weights = torch.FloatTensor(class_weights)\n",
    "\n",
    "# print(f\"\\nMulti-class Classification Weights (for model classes 0-8):\")\n",
    "# for i, weight in enumerate(class_weights):\n",
    "#     original_label = i + 1\n",
    "#     count = attack_counts.get(original_label, 0)\n",
    "#     print(f\"Model class {i} (Attack_{original_label}): count={count}, weight={weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee6f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sqrt\n",
    "attack_counts = Counter(y_train_attacks.numpy())\n",
    "total_attacks = len(y_train_attacks)\n",
    "class_weights_sqrt = []\n",
    "class_frequencies = []\n",
    "\n",
    "for i in range(9):\n",
    "    original_label = i + 1\n",
    "    count = attack_counts.get(original_label, 1)\n",
    "    freq = count / total_attacks\n",
    "    class_frequencies.append(freq)\n",
    "\n",
    "# Calculate sqrt-based weights\n",
    "for freq in class_frequencies:\n",
    "    weight = 1.0 / np.sqrt(freq)\n",
    "    class_weights_sqrt.append(weight)\n",
    "\n",
    "# Normalize\n",
    "total_weight = sum(class_weights_sqrt)\n",
    "class_weights_sqrt = [w * 9 / total_weight for w in class_weights_sqrt]\n",
    "multiclass_weights_sqrt = torch.FloatTensor(class_weights_sqrt)\n",
    "\n",
    "print(f\"\\nSquare Root Frequency Multiclass Weights:\")\n",
    "for i, weight in enumerate(class_weights_sqrt):\n",
    "    original_label = i + 1\n",
    "    count = attack_counts.get(original_label, 0)\n",
    "    print(f\"Class {i} (Attack_{original_label}): count={count}, weight={weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53419ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ENS -> For Extreme Imbalance\n",
    "# attack_counts = Counter(y_train_attacks.numpy())\n",
    "# total_attacks = len(y_train_attacks)\n",
    "\n",
    "\n",
    "# beta = 0.999  # Hyperparameter (0.9-0.999)\n",
    "# effective_num = []\n",
    "# class_weights_ens = []\n",
    "\n",
    "# for i in range(9):\n",
    "#     original_label = i + 1\n",
    "#     count = attack_counts.get(original_label, 1)\n",
    "    \n",
    "#     # Calculate effective number\n",
    "#     en = (1 - beta**count) / (1 - beta) if count > 0 else 1\n",
    "#     effective_num.append(en)\n",
    "\n",
    "# # Normalize ENS weights\n",
    "# for en in effective_num:\n",
    "#     weight = 1.0 / en\n",
    "#     class_weights_ens.append(weight)\n",
    "\n",
    "# # Normalize to sum to number of classes\n",
    "# total_weight = sum(class_weights_ens)\n",
    "# class_weights_ens = [w * 9 / total_weight for w in class_weights_ens]\n",
    "# multiclass_weights_ens = torch.FloatTensor(class_weights_ens)\n",
    "\n",
    "# print(f\"\\nENS-based Multiclass Weights:\")\n",
    "# for i, weight in enumerate(class_weights_ens):\n",
    "#     original_label = i + 1\n",
    "#     count = attack_counts.get(original_label, 0)\n",
    "#     print(f\"Class {i} (Attack_{original_label}): count={count}, weight={weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedccb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Focal Loss Weights\n",
    "\n",
    "# alpha_weights = []\n",
    "# for i in range(9):\n",
    "#     original_label = i + 1\n",
    "#     count = attack_counts.get(original_label, 1)\n",
    "#     freq = count / total_attacks\n",
    "    \n",
    "#     # Alpha weight inversely proportional to frequency\n",
    "#     alpha = (1 - freq) ** 0.5  # Power factor controls aggressiveness\n",
    "#     alpha_weights.append(alpha)\n",
    "\n",
    "# # Normalize alphas to [0.25, 0.75] range for stability\n",
    "# min_alpha, max_alpha = min(alpha_weights), max(alpha_weights)\n",
    "# alpha_weights = [0.25 + 0.5 * (a - min_alpha) / (max_alpha - min_alpha) for a in alpha_weights]\n",
    "# focal_alpha_weights = torch.FloatTensor(alpha_weights)\n",
    "\n",
    "# print(f\"\\nFocal Loss Alpha Weights:\")\n",
    "# for i, weight in enumerate(alpha_weights):\n",
    "#     original_label = i + 1\n",
    "#     count = attack_counts.get(original_label, 0)\n",
    "#     print(f\"Class {i} (Attack_{original_label}): count={count}, alpha={weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweaking here from optimizer to scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdffc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = HierarchicalNIDS(input_features=20, seq_length=10, num_attack_types=9)\n",
    "model = model.to(device)\n",
    "\n",
    "binary_criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
    "multiclass_criterion = nn.CrossEntropyLoss(weight=multiclass_weights_sqrt.to(device))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.01, betas=(0.9, 0.999))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',\n",
    "    patience=5, \n",
    "    factor=0.5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "print(\"Model created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a252c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nModel Configuration:\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Binary loss positive weight: {pos_weight.item():.3f}\")\n",
    "print(f\"Multi-class weights shape: {multiclass_weights_sqrt.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158308f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Starts from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d1ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization parameters\n",
    "GRADIENT_CLIP = 1.0\n",
    "# NOISE_STD = 0.01\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "\n",
    "\n",
    "binary_metrics = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_acc': [], 'val_acc': [],\n",
    "    'train_fpr': [], 'val_fpr': [],\n",
    "    'train_fnr': [], 'val_fnr': []\n",
    "}\n",
    "\n",
    "multiclass_metrics = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_acc': [], 'val_acc': [],\n",
    "    'class_precision': defaultdict(list),\n",
    "    'class_recall': defaultdict(list),\n",
    "    'class_f1': defaultdict(list)\n",
    "}\n",
    "\n",
    "joint_metrics = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'binary_acc': [], 'multiclass_acc': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6804a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_noise_augmentation(batch_x, noise_std=NOISE_STD, training=True):\n",
    "#     if training:\n",
    "#         noise = torch.randn_like(batch_x) * noise_std\n",
    "#         return batch_x + noise\n",
    "#     return batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a72fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_epoch(model, loader, criterion, optimizer, device, ): #noise_std=NOISE_STD\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    for batch_x, batch_y_binary, _ in loader:\n",
    "        # batch_x = add_noise_augmentation(batch_x, noise_std)\n",
    "        batch_x, batch_y_binary = batch_x.to(device), batch_y_binary.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x, stage='binary').squeeze()\n",
    "        loss = criterion(outputs, batch_y_binary)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pred_probs = torch.sigmoid(outputs)\n",
    "        predictions.extend(pred_probs.cpu().detach().numpy())\n",
    "        targets.extend(batch_y_binary.cpu().numpy())\n",
    "    \n",
    "    # Metric evaluation/ Calc.\n",
    "    predictions = np.array(predictions)\n",
    "    targets = np.array(targets)\n",
    "    preds_binary = (predictions > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = np.mean(preds_binary == targets)\n",
    "    tp = np.sum((preds_binary == 1) & (targets == 1))\n",
    "    fp = np.sum((preds_binary == 1) & (targets == 0))\n",
    "    tn = np.sum((preds_binary == 0) & (targets == 0))\n",
    "    fn = np.sum((preds_binary == 0) & (targets == 1))\n",
    "    \n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    \n",
    "    return total_loss / len(loader), accuracy, fpr, fnr, predictions, targets\n",
    "\n",
    "def evaluate_binary(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y_binary, _ in loader:\n",
    "            batch_x, batch_y_binary = batch_x.to(device), batch_y_binary.to(device)\n",
    "            \n",
    "            outputs = model(batch_x, stage='binary').squeeze()\n",
    "            loss = criterion(outputs, batch_y_binary)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pred_probs = torch.sigmoid(outputs)\n",
    "            predictions.extend(pred_probs.cpu().numpy())\n",
    "            targets.extend(batch_y_binary.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    targets = np.array(targets)\n",
    "    preds_binary = (predictions > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = np.mean(preds_binary == targets)\n",
    "    tp = np.sum((preds_binary == 1) & (targets == 1))\n",
    "    fp = np.sum((preds_binary == 1) & (targets == 0))\n",
    "    tn = np.sum((preds_binary == 0) & (targets == 0))\n",
    "    fn = np.sum((preds_binary == 0) & (targets == 1))\n",
    "    \n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    \n",
    "    # Calculate per-class metrics\n",
    "    report = classification_report(targets, preds_binary, \n",
    "                                 target_names=['Normal', 'Attack'], \n",
    "                                 output_dict=True)\n",
    "    \n",
    "    return total_loss / len(loader), accuracy, fpr, fnr, predictions, targets, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884bee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Phase 1: Binary Classification Training\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_val_acc = 0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(15):\n",
    "    # Training\n",
    "    train_loss, train_acc, train_fpr, train_fnr, _, _ = train_binary_epoch(\n",
    "        model, train_loader, binary_criterion, optimizer, device\n",
    "    )\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_acc, val_fpr, val_fnr, val_preds, val_targets, val_report = evaluate_binary(\n",
    "        model, val_loader, binary_criterion, device\n",
    "    )\n",
    "    \n",
    "\n",
    "    binary_metrics['train_loss'].append(train_loss)\n",
    "    binary_metrics['val_loss'].append(val_loss)\n",
    "    binary_metrics['train_acc'].append(train_acc)\n",
    "    binary_metrics['val_acc'].append(val_acc)\n",
    "    binary_metrics['train_fpr'].append(train_fpr)\n",
    "    binary_metrics['val_fpr'].append(val_fpr)\n",
    "    binary_metrics['train_fnr'].append(train_fnr)\n",
    "    binary_metrics['val_fnr'].append(val_fnr)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        # Save model state dict only (not CUDA state)\n",
    "        save_dict = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "        torch.save(save_dict, 'best_binary_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "    \n",
    "    if (epoch + 1) % 3 == 0:\n",
    "        print(f\"\\nEpoch {epoch+1}/15\")\n",
    "        print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, FPR: {train_fpr:.4f}, FNR: {train_fnr:.4f}\")\n",
    "        print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, FPR: {val_fpr:.4f}, FNR: {val_fnr:.4f}\")\n",
    "        print(f\"Val Per-Class Metrics:\")\n",
    "        print(f\"  Normal   - Precision: {val_report['Normal']['precision']:.3f}, \"\n",
    "              f\"Recall: {val_report['Normal']['recall']:.3f}, \"\n",
    "              f\"F1: {val_report['Normal']['f1-score']:.3f}\")\n",
    "        print(f\"  Attack   - Precision: {val_report['Attack']['precision']:.3f}, \"\n",
    "              f\"Recall: {val_report['Attack']['recall']:.3f}, \"\n",
    "              f\"F1: {val_report['Attack']['f1-score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4646f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss plot\n",
    "axes[0, 0].plot(binary_metrics['train_loss'], label='Train Loss')\n",
    "axes[0, 0].plot(binary_metrics['val_loss'], label='Val Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Binary Classification Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0, 1].plot(binary_metrics['train_acc'], label='Train Acc')\n",
    "axes[0, 1].plot(binary_metrics['val_acc'], label='Val Acc')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].set_title('Binary Classification Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# FPR/FNR plot\n",
    "axes[1, 0].plot(binary_metrics['val_fpr'], label='False Positive Rate', color='red')\n",
    "axes[1, 0].plot(binary_metrics['val_fnr'], label='False Negative Rate', color='orange')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Rate')\n",
    "axes[1, 0].set_title('False Positive/Negative Rates')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ROC Curve\n",
    "fpr_roc, tpr_roc, _ = roc_curve(val_targets, val_preds)\n",
    "roc_auc = auc(fpr_roc, tpr_roc)\n",
    "axes[1, 1].plot(fpr_roc, tpr_roc, color='darkorange', lw=2, \n",
    "                label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "axes[1, 1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[1, 1].set_xlim([0.0, 1.0])\n",
    "axes[1, 1].set_ylim([0.0, 1.05])\n",
    "axes[1, 1].set_xlabel('False Positive Rate')\n",
    "axes[1, 1].set_ylabel('True Positive Rate')\n",
    "axes[1, 1].set_title('ROC Curve - Binary Classification')\n",
    "axes[1, 1].legend(loc=\"lower right\")\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overfitting Analysis\n",
    "train_val_gap = binary_metrics['train_acc'][-1] - binary_metrics['val_acc'][-1]\n",
    "print(f\"\\nOverfitting Analysis:\")\n",
    "print(f\"Final Train-Val Accuracy Gap: {train_val_gap:.3f}\")\n",
    "if train_val_gap > 0.1:\n",
    "    print(\"Possible overfitting.\")\n",
    "elif train_val_gap < 0.02:\n",
    "    print(\"Possible underfitting.\")\n",
    "else:\n",
    "    print(\"Well-fitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c3e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiclass_epoch(model, loader, criterion, optimizer, device, ): #noise_std=NOISE_STD\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for batch_x, batch_y in loader:\n",
    "        # batch_x = add_noise_augmentation(batch_x, noise_std)\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = (batch_y - 1).to(device)  # Convert 1-9 to 0-8 for model\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x, stage='multiclass')\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "    return total_loss / len(loader), accuracy, all_preds, all_targets\n",
    "\n",
    "def evaluate_multiclass(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = (batch_y - 1).to(device)  # Convert 1-9 to 0-8 for model\n",
    "            \n",
    "            outputs = model(batch_x, stage='multiclass')\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(batch_y.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "    \n",
    "    # Get per-class metrics (display as Attack_1 to Attack_9)\n",
    "    attack_names = [f'Attack_{i+1}' for i in range(9)]\n",
    "    report = classification_report(all_targets, all_preds, \n",
    "                                 target_names=attack_names, \n",
    "                                 output_dict=True,\n",
    "                                 zero_division=0)\n",
    "    \n",
    "    return total_loss / len(loader), accuracy, all_preds, all_targets, all_probs, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell j: Phase 2 - Multi-class Classification Training\n",
    "print(\"\\n\\nPhase 2: Multi-class Classification Training\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load best binary model\n",
    "model.load_state_dict(torch.load('best_binary_model.pth'))\n",
    "\n",
    "# Freeze feature extractor\n",
    "for param in model.conv1_3.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.conv1_5.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.conv2.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.bilstm.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Optimizer for multi-class head only\n",
    "optimizer_multi = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                                   lr=0.0005, weight_decay=0.01)\n",
    "\n",
    "# Create validation multiclass loader (only attacks)\n",
    "val_attack_mask = y_binary_val_tensor == 1\n",
    "X_val_attacks = X_val_tensor[val_attack_mask]\n",
    "y_val_attacks = y_attack_val_tensor[val_attack_mask]\n",
    "val_multiclass_dataset = TensorDataset(X_val_attacks, y_val_attacks)\n",
    "val_multiclass_loader = DataLoader(val_multiclass_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "best_multi_acc = 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Training\n",
    "    train_loss, train_acc, train_preds, train_targets = train_multiclass_epoch(\n",
    "        model, multiclass_loader, multiclass_criterion, optimizer_multi, device\n",
    "    )\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_acc, val_preds, val_targets, val_probs, val_report = evaluate_multiclass(\n",
    "        model, val_multiclass_loader, multiclass_criterion, device\n",
    "    )\n",
    "    \n",
    "    multiclass_metrics['train_loss'].append(train_loss)\n",
    "    multiclass_metrics['val_loss'].append(val_loss)\n",
    "    multiclass_metrics['train_acc'].append(train_acc)\n",
    "    multiclass_metrics['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Store per-class metrics\n",
    "    for i in range(9):\n",
    "        class_name = f'Attack_{i+1}'\n",
    "        if class_name in val_report:\n",
    "            multiclass_metrics['class_precision'][i].append(val_report[class_name]['precision'])\n",
    "            multiclass_metrics['class_recall'][i].append(val_report[class_name]['recall'])\n",
    "            multiclass_metrics['class_f1'][i].append(val_report[class_name]['f1-score'])\n",
    "    \n",
    "    if val_acc > best_multi_acc:\n",
    "        best_multi_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_multiclass_model.pth')\n",
    "    \n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"\\nEpoch {epoch+1}/10\")\n",
    "        print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "        print(f\"\\nVal Per-Class Metrics:\")\n",
    "        for i in range(9):\n",
    "            class_name = f'Attack_{i+1}'\n",
    "            if class_name in val_report:\n",
    "                print(f\"  {class_name} - P: {val_report[class_name]['precision']:.3f}, \"\n",
    "                      f\"R: {val_report[class_name]['recall']:.3f}, \"\n",
    "                      f\"F1: {val_report[class_name]['f1-score']:.3f}\")\n",
    "        print(f\"  Macro avg - P: {val_report['macro avg']['precision']:.3f}, \"\n",
    "              f\"R: {val_report['macro avg']['recall']:.3f}, \"\n",
    "              f\"F1: {val_report['macro avg']['f1-score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667296ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss plot\n",
    "axes[0, 0].plot(multiclass_metrics['train_loss'], label='Train Loss')\n",
    "axes[0, 0].plot(multiclass_metrics['val_loss'], label='Val Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Multi-class Classification Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0, 1].plot(multiclass_metrics['train_acc'], label='Train Acc')\n",
    "axes[0, 1].plot(multiclass_metrics['val_acc'], label='Val Acc')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].set_title('Multi-class Classification Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "axes[1, 0].set_prop_cycle('color', plt.cm.tab10(np.linspace(0, 1, 9)))\n",
    "for i in range(9):\n",
    "    axes[1, 0].plot(multiclass_metrics['class_f1'][i], label=f'Attack_{i+1}')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('F1-Score')\n",
    "axes[1, 0].set_title('Per-Class F1-Scores')\n",
    "axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(val_targets, val_preds)\n",
    "im = axes[1, 1].imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "axes[1, 1].figure.colorbar(im, ax=axes[1, 1])\n",
    "axes[1, 1].set(xticks=np.arange(cm.shape[1]),\n",
    "                yticks=np.arange(cm.shape[0]),\n",
    "                xticklabels=[f'A{i+1}' for i in range(9)],\n",
    "                yticklabels=[f'A{i+1}' for i in range(9)],\n",
    "                title='Confusion Matrix',\n",
    "                ylabel='True label',\n",
    "                xlabel='Predicted label')\n",
    "plt.setp(axes[1, 1].get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9734d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_joint_epoch(model, loader, binary_criterion, multiclass_criterion, \n",
    "                     optimizer, device, ): #noise_std=NOISE_STD\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    binary_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch_x, batch_y_binary, batch_y_attack in loader:\n",
    "        # batch_x = add_noise_augmentation(batch_x, noise_std)\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y_binary = batch_y_binary.to(device)\n",
    "        batch_y_attack = batch_y_attack.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass for both heads\n",
    "        binary_output, multiclass_output = model(batch_x, stage='both')\n",
    "        binary_output = binary_output.squeeze()\n",
    "        \n",
    "        # Binary loss\n",
    "        binary_loss = binary_criterion(binary_output, batch_y_binary)\n",
    "        \n",
    "        # Multi-class loss only for attack samples\n",
    "        attack_mask = batch_y_binary == 1\n",
    "        if attack_mask.sum() > 0:\n",
    "            attack_labels = batch_y_attack[attack_mask] - 1  # Converting to 1-9 to 0-8\n",
    "            attack_predictions = multiclass_output[attack_mask]\n",
    "            multiclass_loss = multiclass_criterion(attack_predictions, attack_labels)\n",
    "            total_loss_batch = binary_loss + 0.5 * multiclass_loss\n",
    "        else:\n",
    "            total_loss_batch = binary_loss\n",
    "        \n",
    "        total_loss_batch.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += total_loss_batch.item()\n",
    "        predicted = (torch.sigmoid(binary_output) > 0.5).float()\n",
    "        binary_correct += (predicted == batch_y_binary).sum().item()\n",
    "        total_samples += batch_y_binary.size(0)\n",
    "    \n",
    "    return total_loss / len(loader), binary_correct / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0416d2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nPhase 3: Joint Fine-tuning\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Unfreeze all parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "optimizer_joint = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Training\n",
    "    train_loss, train_binary_acc = train_joint_epoch(\n",
    "        model, train_loader, binary_criterion, multiclass_criterion, \n",
    "        optimizer_joint, device\n",
    "    )\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_binary_acc, val_fpr, val_fnr, _, _, val_binary_report = evaluate_binary(\n",
    "        model, val_loader, binary_criterion, device\n",
    "    )\n",
    "    \n",
    "    val_multi_loss, val_multi_acc, _, _, _, val_multi_report = evaluate_multiclass(\n",
    "        model, val_multiclass_loader, multiclass_criterion, device\n",
    "    )\n",
    "    \n",
    "    joint_metrics['train_loss'].append(train_loss)\n",
    "    joint_metrics['val_loss'].append(val_loss)\n",
    "    joint_metrics['binary_acc'].append(val_binary_acc)\n",
    "    joint_metrics['multiclass_acc'].append(val_multi_acc)\n",
    "    \n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"\\nEpoch {epoch+1}/10\")\n",
    "        print(f\"Train - Joint Loss: {train_loss:.4f}, Binary Acc: {train_binary_acc:.4f}\")\n",
    "        print(f\"Val   - Binary Acc: {val_binary_acc:.4f}, Multi Acc: {val_multi_acc:.4f}\")\n",
    "        print(f\"Binary FPR: {val_fpr:.4f}, FNR: {val_fnr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d33e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nFinal Model Evaluation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Testing on final test set\n",
    "test_loss, test_binary_acc, test_fpr, test_fnr, test_preds, test_targets, test_binary_report = evaluate_binary(\n",
    "    model, test_loader, binary_criterion, device\n",
    ")\n",
    "\n",
    "print(f\"\\nTest Set Binary Classification:\")\n",
    "print(f\"Accuracy: {test_binary_acc:.4f}\")\n",
    "print(f\"FPR: {test_fpr:.4f}, FNR: {test_fnr:.4f}\")\n",
    "print(\"\\nBinary Classification Report:\")\n",
    "print(classification_report(test_targets, (test_preds > 0.5).astype(int), \n",
    "                          target_names=['Normal', 'Attack']))\n",
    "\n",
    "# Multi-class evaluation on test set\n",
    "model.eval()\n",
    "test_multi_preds = []\n",
    "test_multi_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_binary_y, batch_multi_y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        \n",
    "        binary_out, multi_out = model(batch_X)\n",
    "        multi_pred = torch.softmax(multi_out, dim=1)\n",
    "        \n",
    "        test_multi_preds.extend(multi_pred.cpu().numpy())\n",
    "        test_multi_targets.extend(batch_multi_y.cpu().numpy())\n",
    "\n",
    "test_multi_preds = np.array(test_multi_preds)\n",
    "test_multi_targets = np.array(test_multi_targets)\n",
    "test_multi_pred_classes = np.argmax(test_multi_preds, axis=1)\n",
    "\n",
    "# Check unique classes in test data\n",
    "unique_classes = sorted(np.unique(test_multi_targets))\n",
    "num_classes = len(unique_classes)\n",
    "\n",
    "print(f\"\\nTest Set Multi-class Classification:\")\n",
    "test_multi_acc = accuracy_score(test_multi_targets, test_multi_pred_classes)\n",
    "print(f\"Accuracy: {test_multi_acc:.4f}\")\n",
    "print(f\"Number of classes found: {num_classes}\")\n",
    "print(f\"Class distribution: {dict(zip(*np.unique(test_multi_targets, return_counts=True)))}\")\n",
    "\n",
    "# Create target names based on actual number of classes\n",
    "if num_classes == 5:\n",
    "    target_names = ['Normal', 'DoS', 'Probe', 'R2L', 'U2R']\n",
    "elif num_classes == 10:\n",
    "    target_names = ['Normal', 'apache2', 'back', 'land', 'neptune', 'pod', 'smurf', 'teardrop', 'mailbomb', 'processtable']\n",
    "else:\n",
    "    target_names = [f'Class_{i}' for i in unique_classes]\n",
    "\n",
    "print(\"\\nMulti-class Classification Report:\")\n",
    "print(classification_report(test_multi_targets, test_multi_pred_classes, \n",
    "                          labels=unique_classes, target_names=target_names))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# Phase comparison\n",
    "phases = ['Binary\\n(15 epochs)', 'Multi-class\\n(10 epochs)', 'Joint\\n(10 epochs)']\n",
    "final_accs = [\n",
    "    binary_metrics['val_acc'][-1] if binary_metrics['val_acc'] else 0,\n",
    "    multiclass_metrics['val_acc'][-1] if multiclass_metrics['val_acc'] else 0,\n",
    "    joint_metrics['binary_acc'][-1] if joint_metrics['binary_acc'] else 0\n",
    "]\n",
    "\n",
    "axes[0,0].bar(phases, final_accs, color=['blue', 'green', 'red'])\n",
    "axes[0,0].set_ylabel('Final Validation Accuracy')\n",
    "axes[0,0].set_title('Performance by Training Phase')\n",
    "axes[0,0].set_ylim(0, 1)\n",
    "\n",
    "# Overfitting analysis\n",
    "train_val_gaps = {\n",
    "    'Binary': binary_metrics['train_acc'][-1] - binary_metrics['val_acc'][-1] if binary_metrics['train_acc'] else 0,\n",
    "    'Multi-class': multiclass_metrics['train_acc'][-1] - multiclass_metrics['val_acc'][-1] if multiclass_metrics['train_acc'] else 0,\n",
    "}\n",
    "\n",
    "axes[0,1].bar(train_val_gaps.keys(), train_val_gaps.values(), color=['orange', 'purple'])\n",
    "axes[0,1].axhline(y=0.1, color='r', linestyle='--', label='Overfitting threshold')\n",
    "axes[0,1].set_ylabel('Train-Val Accuracy Gap')\n",
    "axes[0,1].set_title('Overfitting Analysis')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Final metrics summary\n",
    "metrics_text = f\"\"\"Final Performance Summary:\n",
    "------------------------\n",
    "Binary Classification:\n",
    "  Test Accuracy: {test_binary_acc:.3f}\n",
    "  Test FPR: {test_fpr:.3f}\n",
    "  Test FNR: {test_fnr:.3f}\n",
    "\n",
    "Multi-class (Test):\n",
    "  Test Accuracy: {test_multi_acc:.3f}\n",
    "  Validation Accuracy: {multiclass_metrics['val_acc'][-1]:.3f}\n",
    "  Macro F1: {val_multi_report['macro avg']['f1-score']:.3f}\n",
    "\n",
    "Model Complexity:\n",
    "  Parameters: {sum(p.numel() for p in model.parameters()):,}\n",
    "  Size: ~{sum(p.numel() for p in model.parameters()) * 4 / 1024 / 1024:.2f} MB\n",
    "\"\"\"\n",
    "\n",
    "axes[0,2].text(0.1, 0.5, metrics_text, transform=axes[0,2].transAxes,\n",
    "             fontsize=11, verticalalignment='center', fontfamily='monospace')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "# Binary Classification Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "binary_cm = confusion_matrix(test_targets, (test_preds > 0.5).astype(int))\n",
    "sns.heatmap(binary_cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'], ax=axes[1,0])\n",
    "axes[1,0].set_title('Binary Classification Confusion Matrix')\n",
    "axes[1,0].set_xlabel('Predicted')\n",
    "axes[1,0].set_ylabel('Actual')\n",
    "\n",
    "# Multi-class Confusion Matrix\n",
    "multi_cm = confusion_matrix(test_multi_targets, test_multi_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(multi_cm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=target_names, yticklabels=target_names, ax=axes[1,1])\n",
    "axes[1,1].set_title('Multi-class Classification Confusion Matrix')\n",
    "axes[1,1].set_xlabel('Predicted')\n",
    "axes[1,1].set_ylabel('Actual')\n",
    "plt.setp(axes[1,1].get_xticklabels(), rotation=45, ha='right')\n",
    "plt.setp(axes[1,1].get_yticklabels(), rotation=0)\n",
    "\n",
    "# Training Loss Graph\n",
    "axes[1,2].plot(range(1, len(binary_metrics['train_loss']) + 1), binary_metrics['train_loss'], \n",
    "               'b-', label='Binary Train Loss', linewidth=2)\n",
    "axes[1,2].plot(range(1, len(binary_metrics['val_loss']) + 1), binary_metrics['val_loss'], \n",
    "               'b--', label='Binary Val Loss', linewidth=2)\n",
    "\n",
    "if multiclass_metrics['train_loss']:\n",
    "    offset = len(binary_metrics['train_loss'])\n",
    "    axes[1,2].plot(range(offset + 1, offset + len(multiclass_metrics['train_loss']) + 1), \n",
    "                   multiclass_metrics['train_loss'], 'g-', label='Multi-class Train Loss', linewidth=2)\n",
    "    axes[1,2].plot(range(offset + 1, offset + len(multiclass_metrics['val_loss']) + 1), \n",
    "                   multiclass_metrics['val_loss'], 'g--', label='Multi-class Val Loss', linewidth=2)\n",
    "\n",
    "if joint_metrics['train_loss']:\n",
    "    offset = len(binary_metrics['train_loss']) + len(multiclass_metrics['train_loss'])\n",
    "    axes[1,2].plot(range(offset + 1, offset + len(joint_metrics['train_loss']) + 1), \n",
    "                   joint_metrics['train_loss'], 'r-', label='Joint Train Loss', linewidth=2)\n",
    "    axes[1,2].plot(range(offset + 1, offset + len(joint_metrics['val_loss']) + 1), \n",
    "                   joint_metrics['val_loss'], 'r--', label='Joint Val Loss', linewidth=2)\n",
    "\n",
    "axes[1,2].set_xlabel('Epoch')\n",
    "axes[1,2].set_ylabel('Loss')\n",
    "axes[1,2].set_title('Training and Validation Loss Over Epochs')\n",
    "axes[1,2].legend()\n",
    "axes[1,2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save final model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'binary_metrics': binary_metrics,\n",
    "    'multiclass_metrics': multiclass_metrics,\n",
    "    'joint_metrics': joint_metrics,\n",
    "    'test_results': {\n",
    "        'binary_acc': test_binary_acc,\n",
    "        'multi_acc': test_multi_acc,\n",
    "        'fpr': test_fpr,\n",
    "        'fnr': test_fnr\n",
    "    }\n",
    "}, 'final_hierarchical_nids_model.pth')\n",
    "\n",
    "print(\"\\nModel saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
