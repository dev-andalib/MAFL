{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a144b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score, \n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ee41b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: \"D:\\\\T24\\\\Yeasin's Model\\\\Dataset\\\\GENERAL-UNSWNB15-CAT-SCALED.csv\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df1 = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mD:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mT24\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mYeasin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms Model\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDataset\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mGENERAL-UNSWNB15-CAT-SCALED.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf1.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m display(df1.head(\u001b[32m10\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2430479\\miniconda3\\envs\\MAFL\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2430479\\miniconda3\\envs\\MAFL\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2430479\\miniconda3\\envs\\MAFL\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2430479\\miniconda3\\envs\\MAFL\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2430479\\miniconda3\\envs\\MAFL\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: \"D:\\\\T24\\\\Yeasin's Model\\\\Dataset\\\\GENERAL-UNSWNB15-CAT-SCALED.csv\""
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(r\"D:\\T24\\Yeasin's Model\\Dataset\\GENERAL-UNSWNB15-CAT-SCALED.csv\")\n",
    "print(f\"Dataset Shape: {df1.shape}\")\n",
    "display(df1.head(10))\n",
    "display(df1.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211fd9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_city = LabelEncoder()\n",
    "df1['is_sm_ips_ports'] = le_city.fit_transform(df1['is_sm_ips_ports'])\n",
    "df1['label'] = le_city.fit_transform(df1['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7561072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sloss</th>\n",
       "      <th>dloss</th>\n",
       "      <th>sinpkt</th>\n",
       "      <th>dinpkt</th>\n",
       "      <th>sjit</th>\n",
       "      <th>djit</th>\n",
       "      <th>swin</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>dtcpb</th>\n",
       "      <th>dwin</th>\n",
       "      <th>tcprtt</th>\n",
       "      <th>synack</th>\n",
       "      <th>ackdat</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>response_body_len</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.833334e-07</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.303758e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.333334e-07</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.481877e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.579054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.333335e-08</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.926172e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.111407e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.666667e-07</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.185234e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.000001e-08</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.555704e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.111407e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.666668e-07</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.318657e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.111489e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.111491e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dur     proto  service  state     spkts  dpkts    sbytes  dbytes  \\\n",
       "0  1.833334e-07  0.901515      0.0    0.5  0.000094    0.0  0.000033     0.0   \n",
       "1  1.333334e-07  0.901515      0.0    0.5  0.000094    0.0  0.000121     0.0   \n",
       "2  8.333335e-08  0.901515      0.0    0.5  0.000094    0.0  0.000073     0.0   \n",
       "3  1.000000e-07  0.901515      0.0    0.5  0.000094    0.0  0.000061     0.0   \n",
       "4  1.666667e-07  0.901515      0.0    0.5  0.000094    0.0  0.000146     0.0   \n",
       "5  5.000001e-08  0.901515      0.0    0.5  0.000094    0.0  0.000053     0.0   \n",
       "6  1.000000e-07  0.901515      0.0    0.5  0.000094    0.0  0.000135     0.0   \n",
       "7  4.666668e-07  0.901515      0.0    0.5  0.000094    0.0  0.000095     0.0   \n",
       "8  0.000000e+00  0.045455      0.0    0.5  0.000000    0.0  0.000002     0.0   \n",
       "9  0.000000e+00  0.045455      0.0    0.5  0.000000    0.0  0.000002     0.0   \n",
       "\n",
       "       rate      sttl  dttl     sload  dload  sloss  dloss        sinpkt  \\\n",
       "0  0.090909  0.996078   0.0  0.030121    0.0    0.0    0.0  1.303758e-07   \n",
       "1  0.125000  0.996078   0.0  0.147128    0.0    0.0    0.0  9.481877e-08   \n",
       "2  0.200000  0.996078   0.0  0.142685    0.0    0.0    0.0  5.926172e-08   \n",
       "3  0.166667  0.996078   0.0  0.100200    0.0    0.0    0.0  7.111407e-08   \n",
       "4  0.100000  0.996078   0.0  0.142017    0.0    0.0    0.0  1.185234e-07   \n",
       "5  0.333333  0.996078   0.0  0.174571    0.0    0.0    0.0  3.555704e-08   \n",
       "6  0.166667  0.996078   0.0  0.218214    0.0    0.0    0.0  7.111407e-08   \n",
       "7  0.035714  0.996078   0.0  0.033018    0.0    0.0    0.0  3.318657e-07   \n",
       "8  0.000000  0.000000   0.0  0.000000    0.0    0.0    0.0  7.111489e-01   \n",
       "9  0.000000  0.000000   0.0  0.000000    0.0    0.0    0.0  7.111491e-01   \n",
       "\n",
       "   dinpkt  sjit  djit  swin  stcpb  dtcpb  dwin  tcprtt  synack  ackdat  \\\n",
       "0     0.0   0.0   0.0   0.0    0.0    0.0   0.0     0.0     0.0     0.0   \n",
       "1     0.0   0.0   0.0   0.0    0.0    0.0   0.0     0.0     0.0     0.0   \n",
       "2     0.0   0.0   0.0   0.0    0.0    0.0   0.0     0.0     0.0     0.0   \n",
       "3     0.0   0.0   0.0   0.0    0.0    0.0   0.0     0.0     0.0     0.0   \n",
       "4     0.0   0.0   0.0   0.0    0.0    0.0   0.0     0.0     0.0     0.0   \n",
       "5     0.0   0.0   0.0   0.0    0.0    0.0   0.0     0.0     0.0     0.0   \n",
       "6     0.0   0.0   0.0   0.0    0.0    0.0   0.0     0.0     0.0     0.0   \n",
       "7     0.0   0.0   0.0   0.0    0.0    0.0   0.0     0.0     0.0     0.0   \n",
       "8     0.0   0.0   0.0   0.0    0.0    0.0   0.0     0.0     0.0     0.0   \n",
       "9     0.0   0.0   0.0   0.0    0.0    0.0   0.0     0.0     0.0     0.0   \n",
       "\n",
       "      smean  dmean  trans_depth  response_body_len  ct_srv_src  ct_state_ttl  \\\n",
       "0  0.151351    0.0          0.0                0.0    0.016129      0.333333   \n",
       "1  0.579054    0.0          0.0                0.0    0.016129      0.333333   \n",
       "2  0.344595    0.0          0.0                0.0    0.032258      0.333333   \n",
       "3  0.287838    0.0          0.0                0.0    0.032258      0.333333   \n",
       "4  0.702027    0.0          0.0                0.0    0.032258      0.333333   \n",
       "5  0.248649    0.0          0.0                0.0    0.016129      0.333333   \n",
       "6  0.645946    0.0          0.0                0.0    0.016129      0.333333   \n",
       "7  0.451351    0.0          0.0                0.0    0.032258      0.333333   \n",
       "8  0.014865    0.0          0.0                0.0    0.016129      0.333333   \n",
       "9  0.014865    0.0          0.0                0.0    0.016129      0.333333   \n",
       "\n",
       "   ct_dst_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
       "0    0.000000          0.000000          0.000000        0.015625   \n",
       "1    0.000000          0.000000          0.000000        0.015625   \n",
       "2    0.000000          0.000000          0.000000        0.031250   \n",
       "3    0.017241          0.017241          0.000000        0.031250   \n",
       "4    0.017241          0.017241          0.000000        0.031250   \n",
       "5    0.017241          0.017241          0.000000        0.015625   \n",
       "6    0.017241          0.017241          0.000000        0.015625   \n",
       "7    0.000000          0.000000          0.000000        0.031250   \n",
       "8    0.017241          0.017241          0.022222        0.015625   \n",
       "9    0.017241          0.017241          0.022222        0.015625   \n",
       "\n",
       "   is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
       "0           0.0         0.0               0.0    0.000000    0.016393   \n",
       "1           0.0         0.0               0.0    0.000000    0.016393   \n",
       "2           0.0         0.0               0.0    0.000000    0.032787   \n",
       "3           0.0         0.0               0.0    0.016949    0.032787   \n",
       "4           0.0         0.0               0.0    0.016949    0.032787   \n",
       "5           0.0         0.0               0.0    0.016949    0.016393   \n",
       "6           0.0         0.0               0.0    0.016949    0.016393   \n",
       "7           0.0         0.0               0.0    0.000000    0.032787   \n",
       "8           0.0         0.0               0.0    0.016949    0.016393   \n",
       "9           0.0         0.0               0.0    0.016949    0.016393   \n",
       "\n",
       "   is_sm_ips_ports  attack_cat  label  \n",
       "0                0           6      0  \n",
       "1                0           6      0  \n",
       "2                0           6      0  \n",
       "3                0           6      0  \n",
       "4                0           6      0  \n",
       "5                0           6      0  \n",
       "6                0           6      0  \n",
       "7                0           6      0  \n",
       "8                1           6      0  \n",
       "9                1           6      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea3527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(columns=[\"label\", \"attack_cat\"])\n",
    "y = df1[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9701f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "X_binned = X.apply(lambda col: pd.qcut(col, q=3, labels=False, duplicates='drop'))\n",
    "X_binned_tensor = torch.tensor(X_binned.values, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8edf065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All features:\n",
      "sttl: chi2 = 88836.836, p = 0.000000\n",
      "ct_state_ttl: chi2 = 70613.139, p = 0.000000\n",
      "state: chi2 = 68992.625, p = 0.000000\n",
      "dur: chi2 = 65687.729, p = 0.000000\n",
      "dload: chi2 = 62158.586, p = 0.000000\n",
      "sload: chi2 = 56745.947, p = 0.000000\n",
      "dmean: chi2 = 55864.480, p = 0.000000\n",
      "sinpkt: chi2 = 53189.087, p = 0.000000\n",
      "ct_dst_sport_ltm: chi2 = 52409.818, p = 0.000000\n",
      "spkts: chi2 = 38468.376, p = 0.000000\n",
      "rate: chi2 = 37779.261, p = 0.000000\n",
      "sloss: chi2 = 32393.624, p = 0.000000\n",
      "dpkts: chi2 = 30580.331, p = 0.000000\n",
      "ct_src_dport_ltm: chi2 = 29793.450, p = 0.000000\n",
      "sbytes: chi2 = 29434.911, p = 0.000000\n",
      "dloss: chi2 = 27963.314, p = 0.000000\n",
      "dbytes: chi2 = 26433.767, p = 0.000000\n",
      "smean: chi2 = 26387.501, p = 0.000000\n",
      "proto: chi2 = 25456.297, p = 0.000000\n",
      "ct_dst_src_ltm: chi2 = 24076.592, p = 0.000000\n",
      "ct_srv_dst: chi2 = 19674.673, p = 0.000000\n",
      "stcpb: chi2 = 17082.242, p = 0.000000\n",
      "dtcpb: chi2 = 16516.106, p = 0.000000\n",
      "ct_src_ltm: chi2 = 13667.019, p = 0.000000\n",
      "ct_srv_src: chi2 = 12034.087, p = 0.000000\n",
      "ct_dst_ltm: chi2 = 10309.327, p = 0.000000\n",
      "dttl: chi2 = 2272.354, p = 0.000000\n",
      "djit: chi2 = 2061.109, p = 0.000000\n",
      "sjit: chi2 = 741.525, p = 0.000000\n",
      "service: chi2 = 213.490, p = 0.000000\n",
      "ackdat: chi2 = 90.580, p = 0.000000\n",
      "tcprtt: chi2 = 86.308, p = 0.000000\n",
      "synack: chi2 = 80.391, p = 0.000000\n",
      "dinpkt: chi2 = 13.773, p = 0.000206\n",
      "swin: chi2 = 0.000, p = 1.000000\n",
      "dwin: chi2 = 0.000, p = 1.000000\n",
      "trans_depth: chi2 = 0.000, p = 1.000000\n",
      "response_body_len: chi2 = 0.000, p = 1.000000\n",
      "is_ftp_login: chi2 = 0.000, p = 1.000000\n",
      "ct_ftp_cmd: chi2 = 0.000, p = 1.000000\n",
      "ct_flw_http_mthd: chi2 = 0.000, p = 1.000000\n",
      "is_sm_ips_ports: chi2 = 0.000, p = 1.000000\n",
      "\n",
      "Top 20 features by Chi2:\n",
      "sttl: chi2 = 88836.836, p = 0.00000\n",
      "ct_state_ttl: chi2 = 70613.139, p = 0.00000\n",
      "state: chi2 = 68992.625, p = 0.00000\n",
      "dur: chi2 = 65687.729, p = 0.00000\n",
      "dload: chi2 = 62158.586, p = 0.00000\n",
      "sload: chi2 = 56745.947, p = 0.00000\n",
      "dmean: chi2 = 55864.480, p = 0.00000\n",
      "sinpkt: chi2 = 53189.087, p = 0.00000\n",
      "ct_dst_sport_ltm: chi2 = 52409.818, p = 0.00000\n",
      "spkts: chi2 = 38468.376, p = 0.00000\n",
      "rate: chi2 = 37779.261, p = 0.00000\n",
      "sloss: chi2 = 32393.624, p = 0.00000\n",
      "dpkts: chi2 = 30580.331, p = 0.00000\n",
      "ct_src_dport_ltm: chi2 = 29793.450, p = 0.00000\n",
      "sbytes: chi2 = 29434.911, p = 0.00000\n",
      "dloss: chi2 = 27963.314, p = 0.00000\n",
      "dbytes: chi2 = 26433.767, p = 0.00000\n",
      "smean: chi2 = 26387.501, p = 0.00000\n",
      "proto: chi2 = 25456.297, p = 0.00000\n",
      "ct_dst_src_ltm: chi2 = 24076.592, p = 0.00000\n",
      "\n",
      "Top 20 feature indices: ['sttl', 'ct_state_ttl', 'state', 'dur', 'dload', 'sload', 'dmean', 'sinpkt', 'ct_dst_sport_ltm', 'spkts', 'rate', 'sloss', 'dpkts', 'ct_src_dport_ltm', 'sbytes', 'dloss', 'dbytes', 'smean', 'proto', 'ct_dst_src_ltm']\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "for col in X_binned.columns:\n",
    "    contingency = pd.crosstab(X_binned[col], y)\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "    results.append((col, chi2, p))\n",
    "\n",
    "results_sorted = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nAll features:\")\n",
    "for col, chi2_val, p_val in results_sorted:\n",
    "    print(f\"{col}: chi2 = {chi2_val:.3f}, p = {p_val:5f}\")\n",
    "\n",
    "top = results_sorted[:20]\n",
    "\n",
    "print(\"\\nTop 20 features by Chi2:\")\n",
    "for col, chi2_val, p_val in top:\n",
    "    print(f\"{col}: chi2 = {chi2_val:.3f}, p = {p_val:.5f}\")\n",
    "\n",
    "top_20idx = [col for col, _, _ in top]\n",
    "print(\"\\nTop 20 feature indices:\", top_20idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4946716b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sttl  ct_state_ttl  state           dur     dload     sload  \\\n",
      "0       0.996078      0.333333    0.5  1.833334e-07  0.000000  0.030121   \n",
      "1       0.996078      0.333333    0.5  1.333334e-07  0.000000  0.147128   \n",
      "2       0.996078      0.333333    0.5  8.333335e-08  0.000000  0.142685   \n",
      "3       0.996078      0.333333    0.5  1.000000e-07  0.000000  0.100200   \n",
      "4       0.996078      0.333333    0.5  1.666667e-07  0.000000  0.142017   \n",
      "...          ...           ...    ...           ...       ...       ...   \n",
      "257668  0.996078      0.333333    0.5  1.500000e-07  0.000000  0.008461   \n",
      "257669  0.996078      0.166667    0.4  8.429368e-03  0.000219  0.000001   \n",
      "257670  0.996078      0.333333    0.5  1.500000e-07  0.000000  0.008461   \n",
      "257671  0.996078      0.333333    0.5  1.500000e-07  0.000000  0.008461   \n",
      "257672  0.996078      0.333333    0.5  1.500000e-07  0.000000  0.008461   \n",
      "\n",
      "           dmean        sinpkt  ct_dst_sport_ltm     spkts      rate  \\\n",
      "0       0.000000  1.303758e-07          0.000000  0.000094  0.090909   \n",
      "1       0.000000  9.481877e-08          0.000000  0.000094  0.125000   \n",
      "2       0.000000  5.926172e-08          0.000000  0.000094  0.200000   \n",
      "3       0.000000  7.111407e-08          0.000000  0.000094  0.166667   \n",
      "4       0.000000  1.185234e-07          0.000000  0.000094  0.100000   \n",
      "...          ...           ...               ...       ...       ...   \n",
      "257668  0.000000  1.066711e-07          0.266667  0.000094  0.111111   \n",
      "257669  0.029333  6.447689e-04          0.000000  0.000845  0.000034   \n",
      "257670  0.000000  1.066711e-07          0.044444  0.000094  0.111111   \n",
      "257671  0.000000  1.066711e-07          0.288889  0.000094  0.111111   \n",
      "257672  0.000000  1.066711e-07          0.333333  0.000094  0.111111   \n",
      "\n",
      "           sloss     dpkts  ct_src_dport_ltm    sbytes     dloss    dbytes  \\\n",
      "0       0.000000  0.000000          0.000000  0.000033  0.000000  0.000000   \n",
      "1       0.000000  0.000000          0.000000  0.000121  0.000000  0.000000   \n",
      "2       0.000000  0.000000          0.000000  0.000073  0.000000  0.000000   \n",
      "3       0.000000  0.000000          0.017241  0.000061  0.000000  0.000000   \n",
      "4       0.000000  0.000000          0.017241  0.000146  0.000000  0.000000   \n",
      "...          ...       ...               ...       ...       ...       ...   \n",
      "257668  0.000000  0.000000          0.396552  0.000006  0.000000  0.000000   \n",
      "257669  0.000376  0.000726          0.000000  0.000042  0.000182  0.000024   \n",
      "257670  0.000000  0.000000          0.034483  0.000006  0.000000  0.000000   \n",
      "257671  0.000000  0.000000          0.500000  0.000006  0.000000  0.000000   \n",
      "257672  0.000000  0.000000          0.500000  0.000006  0.000000  0.000000   \n",
      "\n",
      "           smean     proto  ct_dst_src_ltm  \n",
      "0       0.151351  0.901515        0.015625  \n",
      "1       0.579054  0.901515        0.015625  \n",
      "2       0.344595  0.901515        0.031250  \n",
      "3       0.287838  0.901515        0.031250  \n",
      "4       0.702027  0.901515        0.031250  \n",
      "...          ...       ...             ...  \n",
      "257668  0.022297  0.901515        0.359375  \n",
      "257669  0.025676  0.856061        0.015625  \n",
      "257670  0.022297  0.901515        0.187500  \n",
      "257671  0.022297  0.901515        0.453125  \n",
      "257672  0.022297  0.901515        0.453125  \n",
      "\n",
      "[257673 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "top_20columns = top_20idx\n",
    "X_20Ori = df1[top_20columns]\n",
    "\n",
    "print (X_20Ori)\n",
    "\n",
    "X_20Oritensor = torch.tensor(X_20Ori.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(df1['label'].values, dtype=torch.long) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalNIDS(nn.Module):\n",
    "    def __init__(self, input_features=20, seq_length=10, num_attack_types=9):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1_3 = nn.Conv1d(input_features, 16, kernel_size=3, padding=1)\n",
    "        self.conv1_5 = nn.Conv1d(input_features, 8, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(24)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(24, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=32,\n",
    "            hidden_size=16,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "        \n",
    "        self.binary_head = nn.Sequential(\n",
    "            nn.Linear(32, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(24, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 1)\n",
    "        )\n",
    "        \n",
    "        self.multiclass_head = nn.Sequential(\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, num_attack_types)\n",
    "        )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LSTM):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        nn.init.xavier_uniform_(param.data)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        nn.init.orthogonal_(param.data)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.constant_(param.data, 0)\n",
    "    \n",
    "    def attention_net(self, lstm_output):\n",
    "        attention_scores = self.attention(lstm_output)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "        weighted_output = torch.sum(lstm_output * attention_weights, dim=1)\n",
    "        return weighted_output\n",
    "    \n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        conv_3 = self.conv1_3(x)\n",
    "        conv_5 = self.conv1_5(x)\n",
    "        x = torch.cat([conv_3, conv_5], dim=1)\n",
    "        \n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        lstm_out, _ = self.bilstm(x)\n",
    "        \n",
    "        features = self.attention_net(lstm_out)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def forward(self, x, stage='both'):\n",
    "        features = self.extract_features(x)\n",
    "        \n",
    "        if stage == 'binary' or stage == 'both':\n",
    "            binary_output = torch.sigmoid(self.binary_head(features))\n",
    "            \n",
    "        if stage == 'multiclass' or stage == 'both':\n",
    "            multiclass_output = self.multiclass_head(features)\n",
    "            \n",
    "        if stage == 'binary':\n",
    "            return binary_output\n",
    "        elif stage == 'multiclass':\n",
    "            return multiclass_output\n",
    "        else:\n",
    "            return binary_output, multiclass_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_cat_tensor = torch.tensor(df1['attack_cat'].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b987b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y_binary, y_attack_cat, seq_length=10):\n",
    "    num_samples = len(X) - seq_length + 1\n",
    "    X_seq = np.zeros((num_samples, seq_length, X.shape[1]))\n",
    "    y_binary_seq = np.zeros(num_samples)\n",
    "    y_attack_cat_seq = np.zeros(num_samples)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        X_seq[i] = X[i:i+seq_length]\n",
    "        y_binary_seq[i] = y_binary[i+seq_length-1]\n",
    "        y_attack_cat_seq[i] = y_attack_cat[i+seq_length-1]\n",
    "    \n",
    "    return X_seq, y_binary_seq, y_attack_cat_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785995c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_20Ori.values)\n",
    "\n",
    "X_seq, y_binary_seq, y_attack_cat_seq = create_sequences(X_scaled, y_tensor.numpy(), attack_cat_tensor.numpy(), seq_length=10)\n",
    "\n",
    "X_train, X_temp, y_binary_train, y_binary_temp, y_attack_train, y_attack_temp = train_test_split(\n",
    "    X_seq, y_binary_seq, y_attack_cat_seq, test_size=0.6, stratify=y_binary_seq, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_binary_val, y_binary_test, y_attack_val, y_attack_test = train_test_split(\n",
    "    X_temp, y_binary_temp, y_attack_temp, test_size=0.2, stratify=y_binary_temp, random_state=42\n",
    ")\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_binary_train = torch.FloatTensor(y_binary_train)\n",
    "y_binary_val = torch.FloatTensor(y_binary_val)\n",
    "y_binary_test = torch.FloatTensor(y_binary_test)\n",
    "y_attack_train = torch.LongTensor(y_attack_train)\n",
    "y_attack_val = torch.LongTensor(y_attack_val)\n",
    "y_attack_test = torch.LongTensor(y_attack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d5ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique attack types in training data: tensor([0, 1, 2, 3, 4, 5, 7, 8, 9])\n",
      "Number of attack samples for multi-class training: 65869\n"
     ]
    }
   ],
   "source": [
    "attack_indices = y_binary_train == 1\n",
    "y_attack_train_filtered = y_attack_train[attack_indices]\n",
    "X_train_attacks = X_train[attack_indices]\n",
    "\n",
    "unique_attacks = torch.unique(y_attack_train_filtered)\n",
    "print(f\"Unique attack types in training data: {unique_attacks}\")\n",
    "print(f\"Number of attack samples for multi-class training: {len(y_attack_train_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8107b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = torch.tensor([(y_binary_train == 0).sum().float() / (y_binary_train == 1).sum().float()])\n",
    "\n",
    "attack_class_counts = Counter(y_attack_train_filtered.numpy())\n",
    "attack_total_samples = len(y_attack_train_filtered)\n",
    "num_unique_attacks = len(unique_attacks)\n",
    "attack_class_weights = torch.FloatTensor([\n",
    "    attack_total_samples / (num_unique_attacks * attack_class_counts.get(i, 1)) \n",
    "    for i in range(max(unique_attacks) + 1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_binary_train, y_attack_train)\n",
    "val_dataset = TensorDataset(X_val, y_binary_val, y_attack_val)\n",
    "test_dataset = TensorDataset(X_test, y_binary_test, y_attack_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "multiclass_dataset = TensorDataset(X_train_attacks, y_attack_train_filtered)\n",
    "multiclass_loader = DataLoader(multiclass_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b0e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HierarchicalNIDS(input_features=20, seq_length=10, num_attack_types=9)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "binary_criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
    "multiclass_criterion = nn.CrossEntropyLoss(weight=attack_class_weights.to(device))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b04b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df7df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_binary(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_x, batch_y_binary, _ in loader:\n",
    "        batch_x, batch_y_binary = batch_x.to(device), batch_y_binary.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x, stage='binary').squeeze()\n",
    "        loss = criterion(outputs, batch_y_binary)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        correct += (predicted == batch_y_binary).sum().item()\n",
    "        total += batch_y_binary.size(0)\n",
    "    \n",
    "    return total_loss / len(loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee2aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_binary(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    tp = fp = tn = fn = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y_binary, _ in loader:\n",
    "            batch_x, batch_y_binary = batch_x.to(device), batch_y_binary.to(device)\n",
    "            \n",
    "            outputs = model(batch_x, stage='binary').squeeze()\n",
    "            loss = criterion(outputs, batch_y_binary)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            correct += (predicted == batch_y_binary).sum().item()\n",
    "            total += batch_y_binary.size(0)\n",
    "            \n",
    "            tp += ((predicted == 1) & (batch_y_binary == 1)).sum().item()\n",
    "            fp += ((predicted == 1) & (batch_y_binary == 0)).sum().item()\n",
    "            tn += ((predicted == 0) & (batch_y_binary == 0)).sum().item()\n",
    "            fn += ((predicted == 0) & (batch_y_binary == 1)).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return total_loss / len(loader), accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: Training Binary Classifier\n",
      "Epoch 5: Train Loss: 0.3878, Train Acc: 0.7294\n",
      "Val Loss: 0.3842, Val Acc: 0.6392, Val F1: 0.7799\n",
      "Epoch 10: Train Loss: 0.3862, Train Acc: 0.7647\n",
      "Val Loss: 0.3818, Val Acc: 0.7719, Val F1: 0.8477\n",
      "Epoch 15: Train Loss: 0.3843, Train Acc: 0.8035\n",
      "Val Loss: 0.3803, Val Acc: 0.8747, Val F1: 0.9099\n"
     ]
    }
   ],
   "source": [
    "print(\"Phase 1: Training Binary Classifier\")\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(15):\n",
    "    train_loss, train_acc = train_epoch_binary(model, train_loader, binary_criterion, optimizer, device)\n",
    "    val_loss, val_acc, val_prec, val_rec, val_f1 = evaluate_binary(model, val_loader, binary_criterion, device)\n",
    "    scheduler.step()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_binary_model.pth')\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb95402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Binary Classification Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Train Acc')\n",
    "plt.plot(val_accs, label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Binary Classification Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1e349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_binary_model.pth'))\n",
    "\n",
    "for param in model.conv1_3.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.conv1_5.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.conv2.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.bilstm.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer_multi = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9171aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_multiclass(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_x, batch_y in loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x, stage='multiclass')\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "    \n",
    "    return total_loss / len(loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c9894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 2: Training Multi-class Classifier\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "weight tensor should be defined either for all 9 classes or no classes but got weight tensor of shape: [10]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPhase 2: Training Multi-class Classifier\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     train_loss, train_acc = \u001b[43mtrain_epoch_multiclass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulticlass_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulticlass_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_multi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     multi_train_losses.append(train_loss)\n\u001b[32m      8\u001b[39m     multi_train_accs.append(train_acc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtrain_epoch_multiclass\u001b[39m\u001b[34m(model, loader, criterion, optimizer, device)\u001b[39m\n\u001b[32m     10\u001b[39m optimizer.zero_grad()\n\u001b[32m     11\u001b[39m outputs = model(batch_x, stage=\u001b[33m'\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m loss.backward()\n\u001b[32m     14\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2430479\\miniconda3\\envs\\MAFL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2430479\\miniconda3\\envs\\MAFL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2430479\\miniconda3\\envs\\MAFL\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1297\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1304\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2430479\\miniconda3\\envs\\MAFL\\Lib\\site-packages\\torch\\nn\\functional.py:3494\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3493\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3501\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: weight tensor should be defined either for all 9 classes or no classes but got weight tensor of shape: [10]"
     ]
    }
   ],
   "source": [
    "multi_train_losses = []\n",
    "multi_train_accs = []\n",
    "\n",
    "print(\"\\nPhase 2: Training Multi-class Classifier\")\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train_epoch_multiclass(model, multiclass_loader, multiclass_criterion, optimizer_multi, device)\n",
    "    multi_train_losses.append(train_loss)\n",
    "    multi_train_accs.append(train_acc)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Multiclass Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(multi_train_losses, label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Multi-class Classification Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(multi_train_accs, label='Train Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Multi-class Classification Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be672b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer_joint = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_joint(model, loader, binary_criterion, multiclass_criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    binary_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_x, batch_y_binary, batch_y_attack in loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y_binary = batch_y_binary.to(device)\n",
    "        batch_y_attack = batch_y_attack.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        binary_output, multiclass_output = model(batch_x, stage='both')\n",
    "        binary_output = binary_output.squeeze()\n",
    "        \n",
    "        binary_loss = binary_criterion(binary_output, batch_y_binary)\n",
    "        []\n",
    "        attack_mask = batch_y_binary == 1\n",
    "        if attack_mask.sum() > 0:\n",
    "            attack_labels = batch_y_attack[attack_mask]\n",
    "            attack_predictions = multiclass_output[attack_mask]\n",
    "            multiclass_loss = multiclass_criterion(attack_predictions, attack_labels)\n",
    "            total_loss_batch = binary_loss + 0.5 * multiclass_loss\n",
    "        else:\n",
    "            total_loss_batch = binary_loss\n",
    "        \n",
    "        total_loss_batch.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += total_loss_batch.item()\n",
    "        predicted = (torch.sigmoid(binary_output) > 0.5).float()\n",
    "        binary_correct += (predicted == batch_y_binary).sum().item()\n",
    "        total += batch_y_binary.size(0)\n",
    "    \n",
    "    return total_loss / len(loader), binary_correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d54e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_train_losses = []\n",
    "joint_val_losses = []\n",
    "joint_train_accs = []\n",
    "joint_val_accs = []\n",
    "\n",
    "print(\"\\nPhase 3: Joint Fine-tuning\")\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train_epoch_joint(model, train_loader, binary_criterion, multiclass_criterion, optimizer_joint, device)\n",
    "    val_loss, val_acc, val_prec, val_rec, val_f1 = evaluate_binary(model, val_loader, binary_criterion, device)\n",
    "    \n",
    "    joint_train_losses.append(train_loss)\n",
    "    joint_val_losses.append(val_loss)\n",
    "    joint_train_accs.append(train_acc)\n",
    "    joint_val_accs.append(val_acc)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Joint Train Loss: {train_loss:.4f}, Binary Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Binary Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e0e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_train_losses = []\n",
    "joint_val_losses = []\n",
    "joint_train_accs = []\n",
    "joint_val_accs = []\n",
    "\n",
    "print(\"\\nPhase 3: Joint Fine-tuning\")\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train_epoch_joint(model, train_loader, binary_criterion, multiclass_criterion, optimizer_joint, device)\n",
    "    val_loss, val_acc, val_prec, val_rec, val_f1 = evaluate_binary(model, val_loader, binary_criterion, device)\n",
    "    \n",
    "    joint_train_losses.append(train_loss)\n",
    "    joint_val_losses.append(val_loss)\n",
    "    joint_train_accs.append(train_acc)\n",
    "    joint_val_accs.append(val_acc)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Joint Train Loss: {train_loss:.4f}, Binary Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Binary Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e591b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(joint_train_losses, label='Train Loss')\n",
    "plt.plot(joint_val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Joint Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(joint_train_accs, label='Train Acc')\n",
    "plt.plot(joint_val_accs, label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Joint Training Binary Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hierarchical(model, loader, device):\n",
    "    model.eval()\n",
    "    binary_predictions = []\n",
    "    multiclass_predictions = []\n",
    "    true_binary = []\n",
    "    true_attack = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y_binary, batch_y_attack in loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            \n",
    "            binary_output, multiclass_output = model(batch_x, stage='both')\n",
    "            binary_pred = (torch.sigmoid(binary_output.squeeze()) > 0.5).float()\n",
    "            _, multiclass_pred = multiclass_output.max(1)\n",
    "            \n",
    "            binary_predictions.extend(binary_pred.cpu().numpy())\n",
    "            multiclass_predictions.extend(multiclass_pred.cpu().numpy())\n",
    "            true_binary.extend(batch_y_binary.numpy())\n",
    "            true_attack.extend(batch_y_attack.numpy())\n",
    "    \n",
    "    binary_predictions = np.array(binary_predictions)\n",
    "    multiclass_predictions = np.array(multiclass_predictions)\n",
    "    true_binary = np.array(true_binary)\n",
    "    true_attack = np.array(true_attack)\n",
    "    \n",
    "    binary_accuracy = np.mean(binary_predictions == true_binary)\n",
    "    \n",
    "    attack_mask = (binary_predictions == 1) & (true_binary == 1)\n",
    "    if attack_mask.sum() > 0:\n",
    "        multiclass_accuracy = np.mean(multiclass_predictions[attack_mask] == true_attack[attack_mask])\n",
    "    else:\n",
    "        multiclass_accuracy = 0.0\n",
    "    \n",
    "    return binary_accuracy, multiclass_accuracy, binary_predictions, multiclass_predictions, true_binary, true_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8253115",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_acc, multi_acc, binary_preds, multi_preds, true_binary, true_attack = evaluate_hierarchical(model, test_loader, device)\n",
    "print(f\"\\nFinal Test Results:\")\n",
    "print(f\"Binary Classification Accuracy: {binary_acc:.4f}\")\n",
    "print(f\"Multi-class Classification Accuracy (on detected attacks): {multi_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be36b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "cm_binary = confusion_matrix(true_binary, binary_preds)\n",
    "sns.heatmap(cm_binary, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Binary Classification Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.xticks([0.5, 1.5], ['Normal', 'Attack'])\n",
    "plt.yticks([0.5, 1.5], ['Normal', 'Attack'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_mask = (binary_preds == 1) & (true_binary == 1)\n",
    "if attack_mask.sum() > 0:\n",
    "    cm_multi = confusion_matrix(true_attack[attack_mask], multi_preds[attack_mask])\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Multi-class Classification Confusion Matrix (Correctly Detected Attacks)')\n",
    "    plt.xlabel('Predicted Attack Type')\n",
    "    plt.ylabel('True Attack Type')\n",
    "    plt.show()\n",
    "    \n",
    "    unique_attacks = np.unique(true_attack[attack_mask])\n",
    "    print(f\"\\nPer-class accuracy for detected attacks:\")\n",
    "    for attack_type in unique_attacks:\n",
    "        mask = true_attack[attack_mask] == attack_type\n",
    "        if mask.sum() > 0:\n",
    "            acc = (multi_preds[attack_mask][mask] == attack_type).mean()\n",
    "            print(f\"Attack Type {attack_type}: {acc:.4f} ({mask.sum()} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae288bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\nBinary Classification Report:\")\n",
    "print(classification_report(true_binary, binary_preds, target_names=['Normal', 'Attack']))\n",
    "\n",
    "if attack_mask.sum() > 0:\n",
    "    print(\"\\nMulti-class Classification Report (on detected attacks):\")\n",
    "    attack_names = [f'Attack_{i}' for i in range(10)]\n",
    "    print(classification_report(true_attack[attack_mask], multi_preds[attack_mask], \n",
    "                              target_names=attack_names, labels=range(10), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35273c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler': scaler,\n",
    "    'top_20_features': top_20columns,\n",
    "    'model_config': {\n",
    "        'input_features': 20,\n",
    "        'seq_length': 10,\n",
    "        'num_attack_types': 10\n",
    "    },\n",
    "    'performance': {\n",
    "        'binary_accuracy': binary_acc,\n",
    "        'multiclass_accuracy': multi_acc,\n",
    "        'training_history': {\n",
    "            'binary_train_losses': train_losses,\n",
    "            'binary_val_losses': val_losses,\n",
    "            'binary_train_accs': train_accs,\n",
    "            'binary_val_accs': val_accs\n",
    "        }\n",
    "    }\n",
    "}, 'hierarchical_nids_final.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4494c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = sum(p.numel() for p in model.parameters())\n",
    "model_size_mb = model_params * 4 / (1024 * 1024)\n",
    "print(f\"\\nModel Statistics:\")\n",
    "print(f\"Total parameters: {model_params:,}\")\n",
    "print(f\"Model size: {model_size_mb:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAFL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
